import os
import argparse
from datetime import datetime, timezone, timedelta
from typing import Any
from collections import defaultdict
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor

from dotenv import load_dotenv
from github import Github
from github.PullRequest import PullRequest
from slack_sdk import WebClient
import tabulate

# wide chars ëª¨ë“œ í™œì„±í™” (í•œê¸€ í­ ê³„ì‚°ì— wcwidth ì‚¬ìš©)
tabulate.WIDE_CHARS_MODE = True

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê¸°ë³¸ ì„¤ì •
GITHUB_TOKEN = os.environ.get("GITHUB_TOKEN")
SLACK_BOT_TOKEN = os.environ.get("SLACK_BOT_TOKEN")
SLACK_CHANNEL_ID = "C086HAVUFR8"  # ë¦¬ë·° í†µê³„ë¥¼ ë³´ë‚¼ ì±„ë„ ID
ORG_NAME = "team-monolith-product"  # GitHub ì¡°ì§ ì´ë¦„
DAYS = 7  # ì¡°íšŒí•  ë°ì´í„° ê¸°ê°„ (ì¼)


def fetch_pull_requests(
    github_client: Github, repo_owner: str, repo_name: str, days: int
) -> list[PullRequest]:
    """
    ì£¼ì–´ì§„ ê¸°ê°„ ë™ì•ˆì˜ PRì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    # ë‚ ì§œ ê³„ì‚°
    since_date = datetime.now(timezone.utc) - timedelta(days=days)

    # ì €ì¥ì†Œ ì ‘ê·¼
    repo = github_client.get_repo(f"{repo_owner}/{repo_name}")

    # PR ì¡°íšŒ: ëª¨ë“  ìƒíƒœì˜ PRì„ ì¼ê´„ë¡œ ê°€ì ¸ì˜´
    all_pulls = []

    # ì œí•œ ì—†ì´ ëª¨ë“  ê¸°ê°„ ë‚´ PRì„ ê°€ì ¸ì˜´ (ì„±ëŠ¥ ìµœì í™”ë¡œ ì¸í•´ ì œí•œ ì œê±°)
    MAX_PRS_PER_REPO = 100  # ì¶©ë¶„íˆ ë†’ì€ ê°’ìœ¼ë¡œ ì„¤ì •
    pr_count = 0

    # ëª¨ë“  PRì„ ì—…ë°ì´íŠ¸ ë‚ ì§œ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ê°€ì ¸ì˜´ (ê°€ì¥ ìµœê·¼ í•­ëª©ë¶€í„°)
    # state="all"ë¡œ openê³¼ closed PRì„ í•œ ë²ˆì— ê°€ì ¸ì˜´
    all_prs_iterator = repo.get_pulls(state="all", sort="updated", direction="desc")

    # í•„ìš”í•œ ë§Œí¼ë§Œ ê°€ì ¸ì˜¤ê¸° - í˜ì´ì§€ë„¤ì´ì…˜ ìµœì†Œí™”
    for pr in all_prs_iterator:
        # ë‚ ì§œê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì¤‘ë‹¨ (ì—…ë°ì´íŠ¸ ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ìµœì í™” ê°€ëŠ¥)
        if pr.updated_at < since_date and pr.created_at < since_date:
            break

        # í´ë¡œì¦ˆëœ PRì˜ ê²½ìš° ë¨¸ì§€ëœ ê²ƒë§Œ í¬í•¨
        if pr.state == "closed" and pr.merged_at is None:
            continue

        # PRì„ ê²°ê³¼ ëª©ë¡ì— ì¶”ê°€
        all_pulls.append(pr)
        pr_count += 1

        # ìµœëŒ€ ê°œìˆ˜ì— ë„ë‹¬í•˜ë©´ ì¤‘ë‹¨
        if pr_count >= MAX_PRS_PER_REPO:
            break

    return all_pulls


def get_pr_reviews(pr: PullRequest) -> list[dict[str, Any]]:
    """
    PRì˜ ë¦¬ë·°ë¥¼ ê°€ì ¸ì˜¤ê³ , ì‚¬ëŒì´ ì‘ì„±í•œ ë¦¬ë·°ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    """
    reviews = pr.get_reviews()

    # ë´‡ì´ ì‘ì„±í•œ ë¦¬ë·° ì œì™¸
    filtered_reviews = []
    for review in reviews:
        if review.user and review.user.type != "Bot":
            filtered_reviews.append(
                {
                    "id": review.id,
                    "user": review.user.login,
                    "state": review.state,
                    "submitted_at": review.submitted_at,
                    "body": review.body,
                }
            )

    return filtered_reviews


def get_pr_timeline_events(pr: PullRequest) -> list:
    """
    PRì˜ íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    Args:
        pr: í’€ ë¦¬í€˜ìŠ¤íŠ¸ ê°ì²´
        debug: ë””ë²„ê·¸ ë©”ì‹œì§€ ì¶œë ¥ ì—¬ë¶€

    Returns:
        íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ ëª©ë¡
    """
    # PRì— timeline_events ì†ì„±ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸ (ìºì‹±)
    if hasattr(pr, "_timeline_events"):
        return pr._timeline_events

    # PRì„ Issueë¡œ ë³€í™˜í•˜ì—¬ íƒ€ì„ë¼ì¸ì— ì ‘ê·¼
    issue = pr.as_issue()
    timeline = issue.get_timeline()

    # ëª¨ë“  íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ ìˆ˜ì§‘
    events = []

    # íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ ëª©ë¡

    for event in timeline:
        # ì´ë²¤íŠ¸ ì†ì„± í™•ì¸
        event_type = event.event
        event_time = event.created_at

        # ë¦¬ë·° ìš”ì²­/ì œê±° ì´ë²¤íŠ¸
        if event_type in ("review_requested", "review_request_removed"):
            if "requested_reviewer" not in event.raw_data:
                # Team ì´ ìš”ì²­ë˜ëŠ” ê²½ìš° requested_team ë§Œ ì¡´ì¬
                continue

            reviewer = event.raw_data["requested_reviewer"]["login"]
            events.append(
                {
                    "type": event_type,
                    "time": event_time,
                    "reviewer": reviewer,
                }
            )

        elif event_type in ("reviewed"):
            # reviewed ì´ë²¤íŠ¸ëŠ” ë‹¤ë¥¸ ì´ë²¤íŠ¸ì™€ ê·œê²©ì´ ë‹¤ë¦…ë‹ˆë‹¤.
            # actor ëŒ€ì‹  userë¥¼ ì“°ê³ , created_at ëŒ€ì‹  submitted_atì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            reviewer = event.raw_data["user"]["login"]
            event_time = datetime.strptime(
                event.raw_data["submitted_at"], "%Y-%m-%dT%H:%M:%SZ"
            ).replace(
                tzinfo=timezone.utc
            )

            events.append(
                {
                    "type": event_type,
                    "time": event_time,
                    "reviewer": reviewer,
                }
            )

        # Ready for review ì´ë²¤íŠ¸
        elif event_type == "ready_for_review":
            events.append(
                {
                    "type": "ready_for_review",
                    "time": event_time,
                }
            )

    # PR ìƒì„± ì´ë²¤íŠ¸ ì¶”ê°€ (í•­ìƒ ì²« ë²ˆì§¸)
    # TODO: ë¶ˆí•„ìš”í•œ ì½”ë“œ ì œê±°
    events.insert(
        0,
        {
            "type": "created",
            "time": pr.created_at,
            "author": pr.user.login if pr.user else "unknown",
        },
    )

    # ì‹œê°„ìˆœ ì •ë ¬
    events.sort(key=lambda e: e["time"])

    # ìºì‹±
    pr._timeline_events = events
    return events


def calculate_review_response_times(pr: PullRequest) -> dict:
    """
    PRì˜ íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë¦¬ë·°ì–´ë³„ ì‘ë‹µ ì‹œê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        pr: í’€ ë¦¬í€˜ìŠ¤íŠ¸ ê°ì²´
        debug: ë””ë²„ê·¸ ë©”ì‹œì§€ ì¶œë ¥ ì—¬ë¶€

    Returns:
        ë¦¬ë·°ì–´ë³„ ì‘ë‹µ ì‹œê°„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """

    # íƒ€ì„ë¼ì¸ ì´ë²¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    events = get_pr_timeline_events(pr)

    # PRì´ Ready ìƒíƒœê°€ ëœ ì‹œê°„ (ê¸°ë³¸ê°’)
    ready_time = pr.created_at
    for event in events:
        if event["type"] == "ready_for_review":
            ready_time = event["time"]
            break

    # ë¦¬ë·°ì–´ë³„ ìƒíƒœ ì¶”ì 
    reviewer_status = {}  # ë¦¬ë·°ì–´ -> ìƒíƒœ ('ë¯¸ìš”ì²­', 'ìš”ì²­ë¨', 'ì‘ë‹µí•¨')
    reviewer_request_time = {}  # ë¦¬ë·°ì–´ -> ê°€ì¥ ìµœê·¼ ìš”ì²­ ì‹œê°„
    reviewer_last_request_time = (
        {}
    )  # ë¦¬ë·°ì–´ -> ë§ˆì§€ë§‰ìœ¼ë¡œ ìš”ì²­ëœ ì‹œê°„ (ìš”ì²­ ì œê±°ë˜ì–´ë„ ìœ ì§€)

    # PR ë©”íƒ€ë°ì´í„° ì €ì¥ - ë””ë²„ê¹…ì— ìœ ìš©
    pr_metadata = {
        "number": pr.number,
        "title": pr.title,
        "url": pr.html_url,
        "created_at": pr.created_at,
        "updated_at": pr.updated_at,
        "merged_at": pr.merged_at if hasattr(pr, "merged") and pr.merged else None,
        "reviewer_requests": {},  # ë¦¬ë·°ì–´ë³„ ìš”ì²­/ì œê±° ì´ë²¤íŠ¸ ê¸°ë¡
        "reviews": {},  # ë¦¬ë·°ì–´ë³„ ë¦¬ë·° ì œì¶œ ê¸°ë¡
    }

    # ê²°ê³¼ ì €ì¥ìš©
    response_times = {}  # ë¦¬ë·°ì–´ -> [ì‘ë‹µ ì‹œê°„ ëª©ë¡]

    # ì´ˆê¸° ë¦¬ë·°ì–´ ì„¤ì • (PR ìƒì„± ì‹œ ì§€ì •ëœ ë¦¬ë·°ì–´)
    requests = pr.get_review_requests()
    if requests and len(requests) > 0:
        initial_reviewers = [r.login for r in requests[0] if hasattr(r, "login")]
        for reviewer in initial_reviewers:
            reviewer_status[reviewer] = "ìš”ì²­ë¨"
            reviewer_request_time[reviewer] = ready_time  # Ready ì‹œê°„ë¶€í„° ê³„ì‚°
            reviewer_last_request_time[reviewer] = ready_time  # ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„ ê¸°ë¡

    # ì´ë²¤íŠ¸ ì²˜ë¦¬
    for event in events:
        event_type = event["type"]
        event_time = event["time"]

        # ë¦¬ë·° ìš”ì²­ ì´ë²¤íŠ¸
        if event_type == "review_requested" and "reviewer" in event:
            reviewer = event["reviewer"]
            if reviewer:  # ìœ íš¨í•œ ë¦¬ë·°ì–´ í™•ì¸
                # ìš”ì²­ ìƒíƒœë¥¼ ìš”ì²­ë¨ìœ¼ë¡œ ì„¤ì •í•˜ê³  ìš”ì²­ ì‹œê°„ ì—…ë°ì´íŠ¸
                reviewer_status[reviewer] = "ìš”ì²­ë¨"
                reviewer_request_time[reviewer] = event_time
                reviewer_last_request_time[reviewer] = (
                    event_time  # ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„ ì—…ë°ì´íŠ¸
                )

                # PRì˜ ë©”íƒ€ë°ì´í„° ì €ì¥ (ë””ë²„ê¹…ìš©)
                if reviewer not in pr_metadata["reviewer_requests"]:
                    pr_metadata["reviewer_requests"][reviewer] = []
                pr_metadata["reviewer_requests"][reviewer].append(
                    {
                        "action": "requested",
                        "time": str(event_time),
                    }
                )

        # ë¦¬ë·° ìš”ì²­ ì œê±° ì´ë²¤íŠ¸
        elif event_type == "review_request_removed" and "reviewer" in event:
            reviewer = event["reviewer"]
            if reviewer:  # ìœ íš¨í•œ ë¦¬ë·°ì–´ í™•ì¸
                old_status = reviewer_status.get(reviewer, "ì•Œ ìˆ˜ ì—†ìŒ")
                reviewer_status[reviewer] = "ë¯¸ìš”ì²­"

                # PRì˜ ë©”íƒ€ë°ì´í„° ì €ì¥ (ë””ë²„ê¹…ìš©)
                if reviewer not in pr_metadata["reviewer_requests"]:
                    pr_metadata["reviewer_requests"][reviewer] = []
                pr_metadata["reviewer_requests"][reviewer].append(
                    {
                        "action": "removed",
                        "time": str(event_time),
                        "previous_status": old_status,
                    }
                )

                if reviewer in reviewer_request_time:
                    del reviewer_request_time[reviewer]

        # ë¦¬ë·° ì œì¶œ ì´ë²¤íŠ¸
        elif event_type == "reviewed" and "reviewer" in event:
            reviewer = event["reviewer"]

            if not reviewer:  # ìœ íš¨í•˜ì§€ ì•Šì€ ë¦¬ë·°ì–´ ê±´ë„ˆë›°ê¸°
                continue

            # ìê¸° PRì— ìì‹ ì´ ë¦¬ë·°í•œ ê²½ìš° ì œì™¸
            if pr.user and reviewer == pr.user.login:
                continue

            # PR ë©”íƒ€ë°ì´í„°ì— ë¦¬ë·° ì •ë³´ ì €ì¥ (ë””ë²„ê¹…ìš©)
            if reviewer not in pr_metadata["reviews"]:
                pr_metadata["reviews"][reviewer] = []
            pr_metadata["reviews"][reviewer].append(
                {
                    "time": str(event_time),
                    "status": reviewer_status.get(reviewer, "ì•Œ ìˆ˜ ì—†ìŒ"),
                    "last_request": (
                        str(reviewer_last_request_time.get(reviewer, None))
                        if reviewer in reviewer_last_request_time
                        else None
                    ),
                    "current_request": (
                        str(reviewer_request_time.get(reviewer, None))
                        if reviewer in reviewer_request_time
                        else None
                    ),
                }
            )

            # ë¦¬ë·°ì–´ê°€ ìš”ì²­ ìƒíƒœì¸ ê²½ìš°
            if (
                reviewer_status.get(reviewer) == "ìš”ì²­ë¨"
                and reviewer in reviewer_request_time
            ):
                request_time = reviewer_request_time[reviewer]
                time_diff = (
                    event_time - request_time
                ).total_seconds() / 3600  # ì‹œê°„ ë‹¨ìœ„

                # ì‹¤ì œ ê³„ì‚°ëœ ì‹œê°„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                response_time = time_diff

                # ì‘ë‹µ ì‹œê°„ ê¸°ë¡
                if reviewer not in response_times:
                    response_times[reviewer] = []
                response_times[reviewer].append(response_time)

                # ìƒíƒœ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ìš”ì²­ ì¤€ë¹„)
                reviewer_status[reviewer] = "ì‘ë‹µí•¨"
                if reviewer in reviewer_request_time:
                    del reviewer_request_time[reviewer]

            # ë¦¬ë·°ì–´ê°€ ìš”ì²­ ìƒíƒœê°€ ì•„ë‹Œ ê²½ìš° (ë¹„ìš”ì²­ ë¦¬ë·°)
            elif (
                reviewer not in reviewer_status or reviewer_status[reviewer] != "ìš”ì²­ë¨"
            ):
                # ë¹„ìš”ì²­ ë¦¬ë·°ëŠ” í†µê³„ì— í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤.
                continue
                # # ì´ì „ì— ìš”ì²­ëœ ì ì´ ìˆëŠ”ì§€ í™•ì¸
                # if reviewer in reviewer_last_request_time:
                #     # ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„ë¶€í„° ê³„ì‚° (ë¦¬ë·° ìš”ì²­ì´ ì œê±°ëœ ê²½ìš°)
                #     request_time = reviewer_last_request_time[reviewer]
                # else:
                #     # í•œ ë²ˆë„ ìš”ì²­ëœ ì ì´ ì—†ëŠ” ê²½ìš° Ready ì‹œê°„ë¶€í„° ê³„ì‚°
                #     request_time = ready_time

                # # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
                # time_diff = (
                #     event_time - request_time
                # ).total_seconds() / 3600  # ì‹œê°„ ë‹¨ìœ„

                # # Ready ì‹œê°„ë³´ë‹¤ ë¹ ë¥¸ ì´ë²¤íŠ¸ ë°œìƒ(ë§ˆì´ë„ˆìŠ¤ ì‹œê°„)ì€ ë°ì´í„° ë¶ˆì¼ì¹˜ ë¬¸ì œì¼ ìˆ˜ ìˆìŒ

                # # ëª¨ë“  ê²½ìš°ì— ì‹¤ì œ ê³„ì‚°ëœ ì‹œê°„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                # response_time = time_diff

                # # ì‘ë‹µ ì‹œê°„ ê¸°ë¡
                # if reviewer not in response_times:
                #     response_times[reviewer] = []
                # response_times[reviewer].append(response_time)

    # ìµœì¢… ì‘ë‹µ ì‹œê°„ ê²°ê³¼

    return response_times


def process_pr_reviews(pr: PullRequest) -> tuple[dict, PullRequest, dict, int, bool]:
    """
    ë‹¨ì¼ PRì˜ ë¦¬ë·°ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.

    ì‹œê³„ì—´ ê¸°ë°˜ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ë¦¬ë·°ì–´ë³„ ë¦¬ë·° ìš”ì²­-ì‘ë‹µ ì‹œê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        pr: í’€ ë¦¬í€˜ìŠ¤íŠ¸ ê°ì²´
        author_stats: ì €ì í†µê³„ ì •ë³´

    Returns:
        tuple[dict, PullRequest, dict, int, bool]:
            (ë¦¬ë·°ì–´ë³„ í†µê³„, PR, ìš”ì²­ëœ ë¦¬ë·°ì–´ ì •ë³´, ë¦¬ë·° ìˆ˜, ë¦¬ë·° ì¡´ì¬ ì—¬ë¶€)
    """
    if not pr.user:
        return {}, None, {}, 0, False

    author = pr.user.login
    local_reviewer_stats = {}
    open_pr = None
    local_reviewer_to_requested_prs = {}

    # ì—´ë¦° PRì¸ ê²½ìš°
    if pr.state == "open":
        open_pr = pr

        # í˜„ì¬ ìš”ì²­ëœ ë¦¬ë·°ì–´ ì°¾ê¸°
        requested_reviewers = pr.get_review_requests()
        if requested_reviewers and len(requested_reviewers) > 0:
            for user in requested_reviewers[0]:  # [0]ì€ ì‚¬ìš©ì ëª©ë¡, [1]ì€ íŒ€ ëª©ë¡
                if hasattr(user, "login"):
                    local_reviewer_to_requested_prs[user.login] = pr.number

    # ë¦¬ë·° ì •ë³´ ìˆ˜ì§‘
    reviews = get_pr_reviews(pr)
    has_reviews = len(reviews) > 0

    # ì‹œê³„ì—´ ê¸°ë°˜ ë¦¬ë·° ìš”ì²­-ì‘ë‹µ ì‹œê°„ ê³„ì‚°
    reviewer_response_times = calculate_review_response_times(pr)

    # ë¦¬ë·°ì–´ë³„ í†µê³„ êµ¬ì„±
    for reviewer, response_times in reviewer_response_times.items():
        # ìì‹ ì˜ PRì— ìì‹ ì´ ë¦¬ë·°í•œ ê²½ìš° ì œì™¸ (ì´ë¯¸ calculate_review_response_timesì—ì„œ í•„í„°ë§ë¨)
        if reviewer == author:
            continue

        # ë¦¬ë·°ì–´ í†µê³„ ì´ˆê¸°í™”
        if reviewer not in local_reviewer_stats:
            local_reviewer_stats[reviewer] = {
                "review_count": 0,
                "response_times": [],
                "avg_response_time": 0,
                "prs_reviewed": set(),
                "overdue_count": 0,  # 24ì‹œê°„ ì´ˆê³¼ ë¦¬ë·° ìˆ˜
                "pending_reviews": 0,  # ëŒ€ê¸° ì¤‘ì¸ ë¦¬ë·° ìš”ì²­ ìˆ˜
            }

        # ë¦¬ë·° ìˆ˜ ì¦ê°€
        local_reviewer_stats[reviewer]["review_count"] += len(response_times)
        local_reviewer_stats[reviewer]["prs_reviewed"].add(pr.number)

        # ì‘ë‹µ ì‹œê°„ ëª©ë¡ ì¶”ê°€
        local_reviewer_stats[reviewer]["response_times"].extend(response_times)

        # 24ì‹œê°„ ì´ˆê³¼ ë¦¬ë·° ìˆ˜ ê³„ì‚°
        for response_time in response_times:
            if response_time > 24:
                local_reviewer_stats[reviewer]["overdue_count"] += 1

    return (
        local_reviewer_stats,
        open_pr,
        local_reviewer_to_requested_prs,
        len(reviews),
        has_reviews,
    )


def calculate_stats(pull_requests: list[PullRequest]) -> dict[str, dict[str, Any]]:
    """
    PR ë¦¬ë·° í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    - ì‚¬ìš©ìë³„ ë¦¬ë·° ìˆ˜
    - í‰ê·  ì‘ë‹µ ì‹œê°„
    - 24ì‹œê°„ ì´ˆê³¼ ë¦¬ë·° ë¹„ìœ¨

    ThreadPoolExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ PR ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘ì„ ë³‘ë ¬í™”í•©ë‹ˆë‹¤.
    """
    # ë¦¬ë·°ì–´ í†µê³„
    reviewer_stats = {}

    # PR ì‘ì„±ì í†µê³„ (ë°›ì€ ë¦¬ë·° ìˆ˜, ëŒ€ê¸° ì¤‘ì¸ PR ë“±)
    author_stats = {}

    # ë¦¬ë·° ìš”ì²­ëœ PR ëª©ë¡ (reviewer -> PR set)
    reviewer_to_requested_prs = defaultdict(set)

    # ì—´ë¦° PR ëª©ë¡ì„ ì¶”ì 
    open_prs = []

    # ì´ˆê¸°í™” - ëª¨ë“  PR ì‘ì„±ìì˜ í†µê³„
    for pr in pull_requests:
        if pr.user:
            author = pr.user.login
            if author not in author_stats:
                author_stats[author] = {
                    "total_prs": 0,
                    "open_prs": 0,
                    "reviewed_prs": 0,
                    "waiting_for_review": 0,
                }
            author_stats[author]["total_prs"] += 1

    reviews_count = 0

    # ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ ì„¤ì • - ë” ë§ì€ ë™ì‹œ ìš”ì²­ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
    MAX_WORKERS = min(
        50, len(pull_requests)
    )  # GitHub 2ì°¨ ë ˆì´íŠ¸ ì œí•œ ê³ ë ¤í•˜ë©´ì„œ ì¶©ë¶„íˆ ë†’ê²Œ ì„¤ì •

    # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # ëª¨ë“  PRì— ëŒ€í•´ ë³‘ë ¬ë¡œ ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘ ì‘ì—… ì‹œì‘
        futures = {
            executor.submit(process_pr_reviews, pr): (
                pr_index,
                pr,
            )
            for pr_index, pr in enumerate(pull_requests, 1)
        }

        for future in concurrent.futures.as_completed(futures):
            pr_index, pr = futures[future]
            # ê²°ê³¼ ì²˜ë¦¬
            (
                local_reviewer_stats,
                open_pr,
                local_requested_reviewers,
                review_count,
                has_reviews,
            ) = future.result()

            reviews_count += review_count

            # ì—´ë¦° PR ì¶”ê°€
            if open_pr:
                open_prs.append(open_pr)
                author = open_pr.user.login
                author_stats[author]["open_prs"] += 1

            # ë¦¬ë·°ì–´ë³„ ìš”ì²­ PR ì¶”ê°€
            for reviewer, pr_number in local_requested_reviewers.items():
                reviewer_to_requested_prs[reviewer].add(pr_number)

            # ë¦¬ë·°ì–´ë³„ í†µê³„ ê²°ê³¼ ë³‘í•©
            for reviewer, stats in local_reviewer_stats.items():
                if reviewer not in reviewer_stats:
                    reviewer_stats[reviewer] = {
                        "review_count": 0,
                        "response_times": [],
                        "avg_response_time": 0,
                        "prs_reviewed": set(),
                        "overdue_count": 0,
                        "pending_reviews": 0,
                    }

                # í†µê³„ ë³‘í•©
                reviewer_stats[reviewer]["review_count"] += stats["review_count"]
                reviewer_stats[reviewer]["response_times"].extend(
                    stats["response_times"]
                )
                reviewer_stats[reviewer]["prs_reviewed"].update(stats["prs_reviewed"])
                reviewer_stats[reviewer]["overdue_count"] += stats["overdue_count"]

            # ì‘ì„±ì í†µê³„ì— ë¦¬ë·° ë°›ì€ PR ìˆ˜ ì—…ë°ì´íŠ¸
            if has_reviews and pr.user:
                author = pr.user.login
                author_stats[author]["reviewed_prs"] += 1

    # ëŒ€ê¸° ì¤‘ì¸ ë¦¬ë·° ìš”ì²­ ìˆ˜ ì—…ë°ì´íŠ¸
    for reviewer, pr_numbers in reviewer_to_requested_prs.items():
        if reviewer in reviewer_stats:
            reviewer_stats[reviewer]["pending_reviews"] = len(pr_numbers)
        else:
            reviewer_stats[reviewer] = {
                "review_count": 0,
                "avg_response_time": 0,
                "prs_reviewed": set(),
                "overdue_count": 0,
                "pending_reviews": len(pr_numbers),
            }

    # ëŒ€ê¸° ì¤‘ì¸ PR ìˆ˜ ì—…ë°ì´íŠ¸
    for author in author_stats:
        waiting_count = 0
        for pr in open_prs:
            if pr.user and pr.user.login == author:
                waiting_count += 1
        author_stats[author]["waiting_for_review"] = waiting_count

    # í‰ê·  ì‘ë‹µ ì‹œê°„ ë° ì´ˆê³¼ ë¹„ìœ¨ ê³„ì‚°
    for reviewer, data in reviewer_stats.items():
        response_times = data.get("response_times", [])
        if response_times:
            data["avg_response_time"] = sum(response_times) / len(response_times)
            data["overdue_percentage"] = (
                data["overdue_count"] / len(response_times)
            ) * 100

        else:
            data["avg_response_time"] = 0
            data["overdue_percentage"] = 0

        # setì„ ê¸¸ì´ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
        data["prs_reviewed"] = len(data["prs_reviewed"])

        # details í•„ë“œ ì œê±° (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
        if "response_times_details" in data:
            del data["response_times_details"]

    return {"reviewers": reviewer_stats, "authors": author_stats}


def format_reviewer_table(reviewer_stats: dict[str, dict[str, Any]]) -> str:
    """
    ë¦¬ë·°ì–´ í†µê³„ë¥¼ í‘œ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    """
    table_data = []

    for reviewer, data in reviewer_stats.items():
        avg_time = data.get("avg_response_time", 0)
        overdue_percentage = data.get("overdue_percentage", 0)
        review_count = data.get("review_count", 0)
        pending_reviews = data.get("pending_reviews", 0)

        # 24ì‹œê°„ ì´ˆê³¼ ë¹„ìœ¨ì— ë”°ë¥¸ í‘œì‹œ
        status = "âœ…"
        if overdue_percentage > 50:
            status = "âŒ"
        elif overdue_percentage > 25:
            status = "âš ï¸"

        # í…Œì´ë¸” ë°ì´í„° ì¶”ê°€
        table_data.append(
            [
                reviewer,
                f"{avg_time:.1f}h",
                f"{overdue_percentage:.1f}%",
                review_count,
                pending_reviews,
                status,
            ]
        )

    # í‰ê·  ì‘ë‹µ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    table_data.sort(key=lambda x: float(x[1].replace("h", "")))

    # í‘œ í—¤ë”
    headers = ["ë¦¬ë·°ì–´", "í‰ê· ì‘ë‹µ", "24hì´ˆê³¼", "ì™„ë£Œ", "ëŒ€ê¸°", "ìƒíƒœ"]

    # í‘œ ìƒì„±
    return tabulate.tabulate(table_data, headers=headers, tablefmt="simple")


def send_to_slack(
    slack_client: WebClient,
    channel_id: str,
    stats: dict[str, dict[str, Any]],
    days: int,
) -> None:
    """
    í†µê³„ ê²°ê³¼ë¥¼ Slackì— ì „ì†¡í•©ë‹ˆë‹¤.
    """
    reviewer_stats = stats.get("reviewers", {})
    repo_stats = stats.get("repo_stats", {})

    # ë¦¬ë·°ì–´ í†µê³„ í‘œ ìƒì„±
    reviewer_table = format_reviewer_table(reviewer_stats)

    # ë©”ì‹œì§€ ì‘ì„±
    title = "ğŸ“Š ì½”ë“œ ë¦¬ë·° í†µê³„ ë³´ê³ ì„œ"
    subtitle = (
        f"ì§€ë‚œ {days}ì¼ê°„ ë¦¬ë·° í™œë™ (ê¸°ì¤€: {datetime.now().strftime('%Y-%m-%d')})"
    )

    # ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ í‘œ ê°ì‹¸ê¸°
    code_block = f"```\n{reviewer_table}\n```"

    # ì €ì¥ì†Œë³„ í†µê³„
    repo_block = ""
    if repo_stats:
        repo_list = "\n".join(
            [
                f"â€¢ *{repo}*: {count}ê°œ PR"
                for repo, count in repo_stats.items()
                if count > 0
            ]
        )
        if repo_list:
            repo_block = f"*ë¶„ì„ëœ ì €ì¥ì†Œ:*\n{repo_list}"

    # ì¶”ê°€ ì„¤ëª…
    explanation = "â€¢ *í‰ê· ì‘ë‹µ*: ë¦¬ë·° ìš”ì²­ë¶€í„° ì‘ë‹µê¹Œì§€ í‰ê·  ì†Œìš” ì‹œê°„\nâ€¢ *24hì´ˆê³¼*: 24ì‹œê°„ ì´ìƒ ì†Œìš”ëœ ë¦¬ë·° ë¹„ìœ¨\nâ€¢ *ì™„ë£Œ*: ì™„ë£Œí•œ ë¦¬ë·° ìˆ˜\nâ€¢ *ëŒ€ê¸°*: ë¦¬ë·° ìš”ì²­ ë°›ì•˜ìœ¼ë‚˜ ì•„ì§ ì‘ë‹µí•˜ì§€ ì•Šì€ ìˆ˜"

    # ìŠ¬ë™ ë©”ì‹œì§€ ë¸”ë¡ êµ¬ì„±
    blocks = [
        {
            "type": "header",
            "text": {"type": "plain_text", "text": title, "emoji": True},
        },
        {"type": "section", "text": {"type": "mrkdwn", "text": subtitle}},
        {"type": "section", "text": {"type": "mrkdwn", "text": code_block}},
        {"type": "section", "text": {"type": "mrkdwn", "text": explanation}},
    ]

    # ì €ì¥ì†Œ í†µê³„ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if repo_block:
        blocks.append({"type": "divider"})
        blocks.append(
            {"type": "section", "text": {"type": "mrkdwn", "text": repo_block}}
        )

    # ìŠ¬ë™ ë©”ì‹œì§€ ì „ì†¡
    slack_client.chat_postMessage(
        channel=channel_id,
        text=title,
        blocks=blocks,
    )


def get_active_repos(
    github_client: Github, org_name: str, min_activity_days: int = 30
) -> list:
    """
    ì£¼ì–´ì§„ ì¡°ì§ì—ì„œ ìµœê·¼ í™œë™ì´ ìˆëŠ” ì €ì¥ì†Œ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.

    Args:
        github_client: GitHub API í´ë¼ì´ì–¸íŠ¸
        org_name: ì¡°ì§ ì´ë¦„
        min_activity_days: ìµœê·¼ í™œë™ ê¸°ê°„ (ì¼)

    Returns:
        í™œì„± ì €ì¥ì†Œ ëª©ë¡ (owner/name í˜•ì‹)
    """
    # ìµœì†Œ í™œë™ ê¸°ê°„ ê³„ì‚°
    min_activity_date = datetime.now(timezone.utc) - timedelta(days=min_activity_days)

    # ì¡°ì§ì˜ ëª¨ë“  ì €ì¥ì†Œ ê°€ì ¸ì˜¤ê¸°
    org = github_client.get_organization(org_name)
    all_repos = list(org.get_repos())  # í˜ì´ì§€ë„¤ì´ì…˜ ì™„ë£Œë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

    # ìµœê·¼ í™œë™ì´ ìˆëŠ” ì €ì¥ì†Œë§Œ í•„í„°ë§
    active_repos = []

    for repo in all_repos:

        # ë³´ê´€ì²˜ë¦¬ëœ ì €ì¥ì†ŒëŠ” ì œì™¸
        if repo.archived:
            continue

        # forkëœ ì €ì¥ì†ŒëŠ” ì œì™¸
        if repo.fork:
            continue

        # private ì €ì¥ì†Œë§Œ í¬í•¨ (ì„ íƒì )
        if not repo.private:
            continue

        # ìµœê·¼ ì—…ë°ì´íŠ¸ í™•ì¸
        if repo.updated_at >= min_activity_date or repo.pushed_at >= min_activity_date:
            active_repos.append(f"{org_name}/{repo.name}")

    return active_repos


def main():
    """
    GitHub PR ë¦¬ë·° í†µê³„ë¥¼ ìˆ˜ì§‘í•˜ê³  Slackì— ì „ì†¡í•©ë‹ˆë‹¤.

    --dry-run ì˜µì…˜ì´ ì£¼ì–´ì§€ë©´ ì‹¤ì œ ë©”ì‹œì§€ ì „ì†¡ ì—†ì´ ì½˜ì†”ì—ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    parser = argparse.ArgumentParser(description="GitHub PR ë¦¬ë·° í†µê³„ ìˆ˜ì§‘")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ë©”ì‹œì§€ë¥¼ Slackì— ì „ì†¡í•˜ì§€ ì•Šê³  ì½˜ì†”ì—ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤",
    )

    args = parser.parse_args()

    # GitHub API ì´ˆê¸°í™”
    github_client = Github(GITHUB_TOKEN)

    # Slack API ì´ˆê¸°í™”
    slack_client = WebClient(token=SLACK_BOT_TOKEN)

    # ì¡°ì§ì˜ í™œì„± ì €ì¥ì†Œ ì¡°íšŒ
    repositories = get_active_repos(github_client, ORG_NAME)

    # ë³‘ë ¬ë¡œ ê° ì €ì¥ì†Œì˜ PRì„ ê°€ì ¸ì˜´
    all_pull_requests = []
    repo_stats = {}  # ì €ì¥ì†Œë³„ PR ìˆ˜ ì¶”ì 

    # ì €ì¥ì†Œ PR ë³‘ë ¬ ì¡°íšŒë¥¼ ìœ„í•œ í•¨ìˆ˜
    def fetch_repo_prs(repo_index, repo_full_name, days):
        repo_owner, repo_name = repo_full_name.split("/")

        repo_prs = fetch_pull_requests(github_client, repo_owner, repo_name, days)
        return repo_full_name, repo_prs

    # ì €ì¥ì†Œ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì •
    REPO_MAX_WORKERS = min(30, len(repositories))  # ì €ì¥ì†Œ ìˆ˜ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì¡°ì •

    # ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
    with ThreadPoolExecutor(max_workers=REPO_MAX_WORKERS) as executor:
        # ëª¨ë“  ì €ì¥ì†Œì— ëŒ€í•´ ë³‘ë ¬ë¡œ PR ì¡°íšŒ ì‹œì‘
        futures = {
            executor.submit(
                fetch_repo_prs, repo_index, repo_full_name, DAYS
            ): repo_index
            for repo_index, repo_full_name in enumerate(repositories, 1)
        }

        # ê²°ê³¼ ìˆ˜ì§‘
        for future in concurrent.futures.as_completed(futures):
            repo_full_name, repo_prs = future.result()
            if repo_prs:  # ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                all_pull_requests.extend(repo_prs)
                repo_stats[repo_full_name] = len(repo_prs)

    if not all_pull_requests:
        return

    # í†µê³„ ê³„ì‚°
    stats = calculate_stats(all_pull_requests)

    # ë¦¬ë·°ì–´ í†µê³„ í‘œì‹œ
    reviewer_table = format_reviewer_table(stats["reviewers"])

    # ì €ì¥ì†Œë³„ í†µê³„
    repo_activity = "\n".join(
        [f"â€¢ {repo}: {count}ê°œ PR" for repo, count in repo_stats.items() if count > 0]
    )

    if args.dry_run:
        print("=== DRY RUN MODE ===")
        print("ì½”ë“œ ë¦¬ë·° í†µê³„ (ë¦¬ë·°ì–´):")
        print(reviewer_table)
        print("\nì €ì¥ì†Œë³„ PR ìˆ˜:")
        print(repo_activity)
        print("=====================")
    else:
        # Slackì— ì „ì†¡
        # ì €ì¥ì†Œë³„ í†µê³„ë„ í•¨ê»˜ ì „ì†¡
        stats["repo_stats"] = repo_stats
        send_to_slack(slack_client, SLACK_CHANNEL_ID, stats, DAYS)


if __name__ == "__main__":
    main()
